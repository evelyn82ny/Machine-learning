# 신경망 (Neural network)

인간의 두뇌를 모방한 연결주의(connectionism)의 대표적인 AI 기술로 안정적인 학습 가능, 병렬 처리, 에러 감내(fault tolerance) 등의 장점이 있다.<br>
신경망 초기엔 계층이 1개인 단층신경망에 적용하는 퍼셉트론 알고리즘의 한계로 신경망이 침체되었다가 다층신경망이 나오면서 다시 관심받기 시작했다.<br>

뉴런이 연결되어 단뱡향으로 정보를 전달한다.

- 수상돌기(Dendrite) : 다른 신경세포로부터 정보를 받는 곳으로 입력을 의미
- 축삭(Axon) : 신호가 전달되는 부분
- 축삭 말단(Axon terminal) : 다른 신경세포로 정보를 전달로 출력을 의미

시냅스를 통해 뉴런사이에서 정보전달이 이루어지는데 시냅스 강도를 가중치 강도하고 한다. 즉, '정보 전달이 얼마나 잘 이루어지는가' 에 관심을 두고 이를 학습한다.<br>
두 인접 뉴런이 동시에 발화하면(정보 전달이 잘되면) 연결 강도가 증가하는 한다. 즉, 가중치가 증가한다는 뜻인데 이를 적합한 값으로 갱신하도록 학습한다.<br>

## 뉴런 연산

![png](/_img/ml/nn.png) <br>

- 입력과 가중치는 column vector 인데 두 벡터를 곱셈 연산하기 위해 입력 벡터를 전치 행렬(transpose matrix)로 변경해 연산한다.
  - 반대로, 가중치 벡터의 전치 행렬과 입력 행렬의 곱셉 연결과는 동일하다.
- 가중합 : 입력 벡터와 가중치 벡터를 곱셈연산한 결과에 편향(bias)을 더한 값
- 활성화 함수 : 가중합을 활성화 함수에 의해 변환해 출력을 산출

### 편향을 왜 더할까

편향을 계산하지 않고 입력의 전치 행렬과 가중치 행렬의 곱셈 연산한 결과를 **순수 가중입력합**이라고 한다.<br>
순수 가중입력합에 어파인 변환(affine transformation)을 적용하는 효과를 주기 위해 bias를 더한다.<br>

1부터 p까지의 벡터 연산 결과에 편향까지 더한 가중입력합의 수식은 다음과 같다.<br>

![png](/_img/ml/weighted_sum.png) <br>

수식을 단순화 하기 위해 편한을 w0으로 취급하면 오른쪽과 같이 변경된다.<br>